{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ebOc_J4cOuwq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "6b94c139-a909-4c6d-a668-c9e623c58146",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531874808248,
          "user_tz": -420,
          "elapsed": 25276,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# !wget https://uacrmq.bn.files.1drv.com/y4mj9j5D2fVOHlBx2ZSIKE3WG4OhczbFjPXx9ZmAuacUU_ei-QIkEEmFmgTUQMM6Q1mDcGyQxEmFpovEgRlLMGv0mwKyTsa5YckOPgyYD37cRQyTBn9Gjpr6NQPmeFoadP8leIJJW6Xo5_3EpggdufAH3dkG2WurUMQzt__pSBRzYcEm2DQlBG5aFLeCHx9RNBG/input.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-07-18 00:45:43--  https://uacrmq.bn.files.1drv.com/y4mj9j5D2fVOHlBx2ZSIKE3WG4OhczbFjPXx9ZmAuacUU_ei-QIkEEmFmgTUQMM6Q1mDcGyQxEmFpovEgRlLMGv0mwKyTsa5YckOPgyYD37cRQyTBn9Gjpr6NQPmeFoadP8leIJJW6Xo5_3EpggdufAH3dkG2WurUMQzt__pSBRzYcEm2DQlBG5aFLeCHx9RNBG/input.csv\n",
            "Resolving uacrmq.bn.files.1drv.com (uacrmq.bn.files.1drv.com)... 131.253.33.213\n",
            "Connecting to uacrmq.bn.files.1drv.com (uacrmq.bn.files.1drv.com)|131.253.33.213|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 399393515 (381M) [application/octet-stream]\n",
            "Saving to: ‘input.csv’\n",
            "\n",
            "input.csv           100%[===================>] 380.89M  17.2MB/s    in 22s     \n",
            "\n",
            "2018-07-18 00:46:07 (17.0 MB/s) - ‘input.csv’ saved [399393515/399393515]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y5wSrWX6PjPb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84f705c9-541e-40e5-b704-af4fc4c13d12",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531874810388,
          "user_tz": -420,
          "elapsed": 1996,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab  input.csv\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WMP-JQCDPMBT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "outputId": "6fac943e-7390-435c-eb25-cc708300e677",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531874826258,
          "user_tz": -420,
          "elapsed": 15791,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/f3/37504f07651330ddfdefa631ca5246974a60d0908216539efda842fd080f/gensim-3.5.0-cp36-cp36m-manylinux1_x86_64.whl (23.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 23.5MB 1.2MB/s \n",
            "\u001b[?25hCollecting smart-open>=1.2.1 (from gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/cf/3d/5f3a9a296d0ba8e00e263a8dee76762076b9eb5ddc254ccaa834651c8d65/smart_open-1.6.0.tar.gz\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (0.19.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.5)\n",
            "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.4MB 11.7MB/s \n",
            "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/c2/240bf5174132cb575763f0096d3df9643036399e1275df9c20cee88ece07/boto3-1.7.59-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 21.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.4.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Collecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 18.8MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
            "Collecting botocore<1.11.0,>=1.10.59 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/77/26dab42032978b5f547869836523701279fc207d4affcad74b4b6d65f13f/botocore-1.10.59-py2.py3-none-any.whl (4.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 4.4MB 6.4MB/s \n",
            "\u001b[?25hCollecting docutils>=0.10 (from botocore<1.11.0,>=1.10.59->boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
            "\u001b[K    100% |████████████████████████████████| 552kB 13.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.11.0,>=1.10.59->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Building wheels for collected packages: smart-open, bz2file\n",
            "  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/73/f1/9b/ccf93d4ba073b6f79b1ed9df68ab5ce048d8136d0efcf90b30\n",
            "  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
            "Successfully built smart-open bz2file\n",
            "Installing collected packages: boto, bz2file, docutils, jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
            "Successfully installed boto-2.49.0 boto3-1.7.59 botocore-1.10.59 bz2file-0.98 docutils-0.14 gensim-3.5.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.6.0\n",
            "[nltk_data] Downloading package stopwords to /content/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /content/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /content/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "JMD9GPETIL2p",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21371f40-e7ba-4566-dbd7-2ee784d16490",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531874835598,
          "user_tz": -420,
          "elapsed": 9224,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# languange processing imports\n",
        "import nltk\n",
        "from gensim.corpora import Dictionary\n",
        "# preprocessing imports\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "# model imports\n",
        "from gensim.models.ldamulticore import LdaMulticore\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# hyperparameter training imports\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# visualization imports\n",
        "\n",
        "import seaborn as sns\n",
        "import base64\n",
        "import io\n",
        "%matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "s7QB1HO2IL2z",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# data = pd.read_csv(\"output.csv\",encoding='utf-8')\n",
        "# authors = []\n",
        "# titles = []\n",
        "\n",
        "# author__title = []\n",
        "# for name in glob.glob(os.path.join(\"txt\",\"*.txt\")):\n",
        "    \n",
        "#     authortitle= name.split(\"\\\\\")[-1]\n",
        "#     author = authortitle.split(\"___\")[0]\n",
        "#     title = authortitle.split(\"___\")[1].split(\".\")[0]\n",
        "#     authors.append(author)\n",
        "#     titles.append(title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i3NacU0QIL23",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# contexts = []\n",
        "# for path in glob.glob(os.path.join(\"txt\",\"*.txt\")):\n",
        "#     f1 = open(path, 'r', errors = 'ignore', encoding='utf-8')\n",
        "\n",
        "#     text = f1.read().rstrip()\n",
        "#     contexts.append(text)\n",
        "# df = pd.DataFrame({'author':authors})\n",
        "# df['context'] = contexts\n",
        "# df.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3wgnicN4IL27",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"input.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VNuRN7WbIL3A",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "31f18722-c2d6-42ee-9b93-8ee649344720",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531874847798,
          "user_tz": -420,
          "elapsed": 4432,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(data.shape[0]):\n",
        "    rmtext = data.author[i].split(' ')\n",
        "    for text in rmtext:\n",
        "        data.context[i] = data.context[i].replace(text,'')\n",
        "\n",
        "data['context'] = data['context'].str.replace('\\r', '')\n",
        "data['context'] = data['context'].str.replace('\\n', ' ')\n",
        "data['context'] = data['context'].str.replace(\"\\'s\", '')\n",
        "data['context'] = data['context'].str.replace(\"\\'s\", '')\n",
        "data['context'] = data['context'].str.replace(\"\\'\", '')\n",
        "data['context'] = data['context'].str.replace(\"'\", '')\n",
        "# def remove_non_ascii(text):\n",
        "#     return ''.join(i for i in text if ord(i)<128)\n",
        " \n",
        "#data['context'] = data['context'].apply(remove_non_ascii)\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "# stop = stopwords.words('english')\n",
        "# test['tweet'].apply(lambda x: [item for item in x if item not in stop])\n",
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Andrew Lang</td>\n",
              "      <td>A Collection of Ballads     Contents:  Sir Pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Andrew Lang</td>\n",
              "      <td>A MONK OF FIFE Being the Chronicle written ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Andrew Lang</td>\n",
              "      <td>A SHORT HISTORY OF SCOTLAND   CHAPTER I.  SCO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Andrew Lang</td>\n",
              "      <td>ADVENTURES AMONG BOOKS by     Contents:  Pre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Andrew Lang</td>\n",
              "      <td>ALFRED TENNYSON  by       INTRODUCTION    In ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        author                                            context\n",
              "0  Andrew Lang   A Collection of Ballads     Contents:  Sir Pa...\n",
              "1  Andrew Lang     A MONK OF FIFE Being the Chronicle written ...\n",
              "2  Andrew Lang   A SHORT HISTORY OF SCOTLAND   CHAPTER I.  SCO...\n",
              "3  Andrew Lang    ADVENTURES AMONG BOOKS by     Contents:  Pre...\n",
              "4  Andrew Lang   ALFRED TENNYSON  by       INTRODUCTION    In ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "JXPUC9JeIL3F",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "a6fa477b-0cee-449e-dc1f-fbbf829e7302",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531874848949,
          "user_tz": -420,
          "elapsed": 749,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "data.author.value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "William Wymark Jacobs        97\n",
              "George Alfred Henty          89\n",
              "R M Ballantyne               88\n",
              "Nathaniel Hawthorne          86\n",
              "William Dean Howells         84\n",
              "Robert Louis Stevenson       79\n",
              "Henry James                  72\n",
              "Anthony Trollope             71\n",
              "Charles Dickens              61\n",
              "Charlotte Mary Yonge         60\n",
              "Andrew Lang                  60\n",
              "Bret Harte                   58\n",
              "Edward Stratemeyer           58\n",
              "Sir Arthur Conan Doyle       57\n",
              "Edward Phillips Oppenheim    53\n",
              "Name: author, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "gSZCRfgzIZIi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "data['wordcount'] = data['context'].str.count(\" \") + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a6ALa5DnOleT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "671c089d-db3d-4870-bf35-adfa8e058376",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531874856880,
          "user_tz": -420,
          "elapsed": 688,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(data.wordcount.min())\n",
        "print(data.wordcount.max())\n",
        "print(data.wordcount.mean())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "732\n",
            "399755\n",
            "69746.08108108108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OXgORfYtIL3K",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "awSrSfEwIL3S",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "laiUZe0fIL3V",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.context, data.author, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IDW9in70IL3b",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vector = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
        "\n",
        "\n",
        "tfidf_train = tfidf_vector.fit_transform(X_train).toarray()\n",
        "tfidf_test = tfidf_vector.transform(X_test).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uoZKxWT7IL3f",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa8829b7-6017-4bad-e4f6-9cb68690602d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531875071883,
          "user_tz": -420,
          "elapsed": 696,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "tfidf_train.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(858, 636851)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "7juR_zLFIL3k",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3fa2b91-2487-4cf4-f9c0-02dc2cf4cedd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531875072829,
          "user_tz": -420,
          "elapsed": 648,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "tfidf_test.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(215, 636851)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "0IsMI375IL3r",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "9b7b48c9-88b7-4771-d4d7-072106cb43da",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531875109027,
          "user_tz": -420,
          "elapsed": 35824,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc_model = RandomForestClassifier(n_estimators=100, random_state=888)\n",
        "rfc_model.fit(tfidf_train,y_train)\n",
        "pr = rfc_model.predict(tfidf_test)\n",
        "print(classification_report(y_test, pr))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                           precision    recall  f1-score   support\n",
            "\n",
            "              Andrew Lang       0.93      1.00      0.96        13\n",
            "         Anthony Trollope       0.93      0.87      0.90        15\n",
            "               Bret Harte       1.00      0.88      0.93         8\n",
            "          Charles Dickens       0.88      0.70      0.78        10\n",
            "     Charlotte Mary Yonge       1.00      0.76      0.87        17\n",
            "Edward Phillips Oppenheim       1.00      1.00      1.00        14\n",
            "       Edward Stratemeyer       1.00      1.00      1.00        10\n",
            "      George Alfred Henty       0.96      0.96      0.96        23\n",
            "              Henry James       1.00      1.00      1.00        17\n",
            "      Nathaniel Hawthorne       0.62      1.00      0.77        15\n",
            "           R M Ballantyne       1.00      0.93      0.96        14\n",
            "   Robert Louis Stevenson       1.00      0.94      0.97        17\n",
            "   Sir Arthur Conan Doyle       1.00      0.57      0.73         7\n",
            "     William Dean Howells       0.92      0.67      0.77        18\n",
            "    William Wymark Jacobs       0.68      1.00      0.81        17\n",
            "\n",
            "              avg / total       0.92      0.90      0.90       215\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FIW97e7kIL3x",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rY0eADqxIL30",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "95316c47-be0b-458f-d567-bbd5335e3077",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531875149115,
          "user_tz": -420,
          "elapsed": 38962,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "pr = gnb.fit(tfidf_train, y_train)\n",
        "pr = gnb.predict(tfidf_test)\n",
        "print(classification_report(y_test, pr))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                           precision    recall  f1-score   support\n",
            "\n",
            "              Andrew Lang       1.00      0.69      0.82        13\n",
            "         Anthony Trollope       0.65      0.87      0.74        15\n",
            "               Bret Harte       1.00      1.00      1.00         8\n",
            "          Charles Dickens       0.71      1.00      0.83        10\n",
            "     Charlotte Mary Yonge       0.65      1.00      0.79        17\n",
            "Edward Phillips Oppenheim       1.00      1.00      1.00        14\n",
            "       Edward Stratemeyer       1.00      1.00      1.00        10\n",
            "      George Alfred Henty       0.79      1.00      0.88        23\n",
            "              Henry James       1.00      0.76      0.87        17\n",
            "      Nathaniel Hawthorne       1.00      0.60      0.75        15\n",
            "           R M Ballantyne       1.00      1.00      1.00        14\n",
            "   Robert Louis Stevenson       1.00      0.88      0.94        17\n",
            "   Sir Arthur Conan Doyle       1.00      0.57      0.73         7\n",
            "     William Dean Howells       1.00      0.83      0.91        18\n",
            "    William Wymark Jacobs       1.00      0.88      0.94        17\n",
            "\n",
            "              avg / total       0.91      0.88      0.88       215\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kqLRWvS2IL36",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder_X=LabelEncoder()\n",
        "y_trainenc = labelencoder_X.fit_transform(y_train)\n",
        "y_testenc=labelencoder_X.transform(y_test)\n",
        "from keras import utils as np_utils\n",
        "y_train1h = np_utils.to_categorical(y_trainenc, 15)\n",
        "y_test1h = np_utils.to_categorical(y_testenc, 15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m4dFp4fXWnF_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OqXDYX-KIL3-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "outputId": "17c1b947-3d5e-4bc5-c91e-ca417cfefacd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531875258928,
          "user_tz": -420,
          "elapsed": 107642,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import keras\n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Dense(512, activation='relu', input_dim=tfidf_train.shape[1]))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(15, activation='softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "            optimizer = keras.optimizers.RMSprop(),\n",
        "             metrics=['accuracy'])\n",
        "model.fit(tfidf_train, y_train1h,\n",
        "        batch_size=128,\n",
        "        epochs=10,\n",
        "        verbose=1,\n",
        "        validation_data=(tfidf_test, y_test1h))\n",
        "score = model.evaluate(tfidf_test, y_test1h, verbose=0)\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "classes = model.predict_classes(tfidf_test, batch_size = None)\n",
        "print(classification_report(y_testenc, classes))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 858 samples, validate on 215 samples\n",
            "Epoch 1/10\n",
            "858/858 [==============================] - 22s 25ms/step - loss: 2.5141 - acc: 0.1946 - val_loss: 2.3677 - val_acc: 0.2837\n",
            "Epoch 2/10\n",
            "858/858 [==============================] - 8s 10ms/step - loss: 1.4350 - acc: 0.5699 - val_loss: 1.1135 - val_acc: 0.6651\n",
            "Epoch 3/10\n",
            "858/858 [==============================] - 9s 10ms/step - loss: 0.3345 - acc: 0.9138 - val_loss: 0.2210 - val_acc: 0.9488\n",
            "Epoch 4/10\n",
            "858/858 [==============================] - 9s 10ms/step - loss: 0.0273 - acc: 1.0000 - val_loss: 0.1358 - val_acc: 0.9674\n",
            "Epoch 5/10\n",
            "858/858 [==============================] - 9s 10ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0863 - val_acc: 0.9860\n",
            "Epoch 6/10\n",
            "858/858 [==============================] - 9s 10ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0764 - val_acc: 0.9907\n",
            "Epoch 7/10\n",
            "858/858 [==============================] - 9s 10ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0684 - val_acc: 0.9907\n",
            "Epoch 8/10\n",
            "858/858 [==============================] - 9s 11ms/step - loss: 8.1108e-04 - acc: 1.0000 - val_loss: 0.0592 - val_acc: 0.9907\n",
            "Epoch 9/10\n",
            "858/858 [==============================] - 9s 11ms/step - loss: 4.3069e-04 - acc: 1.0000 - val_loss: 0.0568 - val_acc: 0.9860\n",
            "Epoch 10/10\n",
            "858/858 [==============================] - 9s 10ms/step - loss: 2.6315e-04 - acc: 1.0000 - val_loss: 0.0562 - val_acc: 0.9907\n",
            "Test loss: 0.056187048138574114\n",
            "Test accuracy: 0.9906976744186047\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       1.00      1.00      1.00        13\n",
            "          1       1.00      1.00      1.00        15\n",
            "          2       1.00      1.00      1.00         8\n",
            "          3       1.00      1.00      1.00        10\n",
            "          4       1.00      1.00      1.00        17\n",
            "          5       1.00      1.00      1.00        14\n",
            "          6       1.00      1.00      1.00        10\n",
            "          7       0.96      1.00      0.98        23\n",
            "          8       1.00      1.00      1.00        17\n",
            "          9       0.94      1.00      0.97        15\n",
            "         10       1.00      1.00      1.00        14\n",
            "         11       1.00      1.00      1.00        17\n",
            "         12       1.00      0.86      0.92         7\n",
            "         13       1.00      0.94      0.97        18\n",
            "         14       1.00      1.00      1.00        17\n",
            "\n",
            "avg / total       0.99      0.99      0.99       215\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n266Zaq4IL4C",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "del tfidf_vector\n",
        "del tfidf_train\n",
        "del tfidf_test "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4dJjb0RZIL4F",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02dcd4c8-9122-4f36-d70b-f527c59535ee",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531875403378,
          "user_tz": -420,
          "elapsed": 137764,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "count_vect.fit(data.context)\n",
        "X_train_counts = count_vect.transform(X_train)\n",
        "X_test_counts = count_vect.transform(X_test)\n",
        "X_train_counts.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(858, 188799)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "UXXnwnryIL4M",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3acd2d2f-a63e-4338-df53-1096789f21fc",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531875404906,
          "user_tz": -420,
          "elapsed": 651,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X_test_counts.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(215, 188799)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "YH3wG2ptIL4Q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "a06a1cd0-8063-4501-f7de-3947faecfa27",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531875413099,
          "user_tz": -420,
          "elapsed": 7929,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "rfc_model2 = RandomForestClassifier(n_estimators=100, random_state=888)\n",
        "rfc_model2.fit(X_train_counts,y_train)\n",
        "pr = rfc_model2.predict(X_test_counts)\n",
        "print(classification_report(y_test, pr))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                           precision    recall  f1-score   support\n",
            "\n",
            "              Andrew Lang       0.81      1.00      0.90        13\n",
            "         Anthony Trollope       1.00      1.00      1.00        15\n",
            "               Bret Harte       1.00      0.88      0.93         8\n",
            "          Charles Dickens       0.80      0.80      0.80        10\n",
            "     Charlotte Mary Yonge       1.00      0.71      0.83        17\n",
            "Edward Phillips Oppenheim       1.00      1.00      1.00        14\n",
            "       Edward Stratemeyer       1.00      1.00      1.00        10\n",
            "      George Alfred Henty       0.96      0.96      0.96        23\n",
            "              Henry James       0.94      1.00      0.97        17\n",
            "      Nathaniel Hawthorne       0.79      1.00      0.88        15\n",
            "           R M Ballantyne       1.00      0.93      0.96        14\n",
            "   Robert Louis Stevenson       0.94      0.94      0.94        17\n",
            "   Sir Arthur Conan Doyle       1.00      0.57      0.73         7\n",
            "     William Dean Howells       1.00      0.78      0.88        18\n",
            "    William Wymark Jacobs       0.74      1.00      0.85        17\n",
            "\n",
            "              avg / total       0.93      0.92      0.91       215\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IQlo4jhgIL4X",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "017f3193-56e0-4fc3-e820-1a615d583167",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531875426933,
          "user_tz": -420,
          "elapsed": 13708,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "pr = gnb.fit(X_train_counts.toarray(), y_train)\n",
        "pr = gnb.predict(X_test_counts.toarray())\n",
        "print(classification_report(y_test, pr))\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                           precision    recall  f1-score   support\n",
            "\n",
            "              Andrew Lang       0.67      0.77      0.71        13\n",
            "         Anthony Trollope       0.54      0.47      0.50        15\n",
            "               Bret Harte       0.83      0.62      0.71         8\n",
            "          Charles Dickens       0.67      0.80      0.73        10\n",
            "     Charlotte Mary Yonge       0.55      0.94      0.70        17\n",
            "Edward Phillips Oppenheim       0.83      0.36      0.50        14\n",
            "       Edward Stratemeyer       0.73      0.80      0.76        10\n",
            "      George Alfred Henty       0.76      0.83      0.79        23\n",
            "              Henry James       0.62      0.29      0.40        17\n",
            "      Nathaniel Hawthorne       0.53      0.60      0.56        15\n",
            "           R M Ballantyne       1.00      0.79      0.88        14\n",
            "   Robert Louis Stevenson       0.80      0.71      0.75        17\n",
            "   Sir Arthur Conan Doyle       0.45      0.71      0.56         7\n",
            "     William Dean Howells       0.85      0.61      0.71        18\n",
            "    William Wymark Jacobs       0.70      0.94      0.80        17\n",
            "\n",
            "              avg / total       0.71      0.68      0.67       215\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tg1AyeTXufxg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nrw2iulyVZ4y",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "outputId": "ff79b56e-7c68-4610-e7ca-86a0586c3f6b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531875465813,
          "user_tz": -420,
          "elapsed": 37571,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train_counts.toarray())\n",
        "X_train_counts_scale = scaler.transform(X_train_counts.toarray())\n",
        "X_test_counts_scale = scaler.transform(X_test_counts.toarray())\n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Dense(512, activation='relu', input_dim=X_train_counts_scale.shape[1]))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(15, activation='softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "            optimizer = keras.optimizers.RMSprop(),\n",
        "             metrics=['accuracy'])\n",
        "model.fit(X_train_counts_scale, y_train1h,\n",
        "        batch_size=128,\n",
        "        epochs=10,\n",
        "        verbose=1,\n",
        "        validation_data=(X_test_counts_scale, y_test1h))\n",
        "score = model.evaluate(X_test_counts_scale, y_test1h, verbose=0)\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "classes = model.predict_classes(X_test_counts_scale, batch_size = None)\n",
        "print(classification_report(y_testenc, classes))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 858 samples, validate on 215 samples\n",
            "Epoch 1/10\n",
            "858/858 [==============================] - 5s 6ms/step - loss: 2.9518 - acc: 0.1480 - val_loss: 2.3139 - val_acc: 0.2977\n",
            "Epoch 2/10\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 1.6039 - acc: 0.6166 - val_loss: 1.3745 - val_acc: 0.7814\n",
            "Epoch 3/10\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5657 - acc: 0.9662 - val_loss: 0.8030 - val_acc: 0.8233\n",
            "Epoch 4/10\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.1885 - acc: 0.9848 - val_loss: 0.1654 - val_acc: 0.9814\n",
            "Epoch 5/10\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.0368 - acc: 0.9953 - val_loss: 0.1154 - val_acc: 0.9860\n",
            "Epoch 6/10\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.1057 - val_acc: 0.9814\n",
            "Epoch 7/10\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0714 - val_acc: 0.9907\n",
            "Epoch 8/10\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.1114 - val_acc: 0.9767\n",
            "Epoch 9/10\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1227 - val_acc: 0.9767\n",
            "Epoch 10/10\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.3470 - val_acc: 0.9442\n",
            "Test loss: 0.3469815534907718\n",
            "Test accuracy: 0.9441860465116279\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       1.00      1.00      1.00        13\n",
            "          1       1.00      0.53      0.70        15\n",
            "          2       0.80      1.00      0.89         8\n",
            "          3       0.91      1.00      0.95        10\n",
            "          4       0.68      1.00      0.81        17\n",
            "          5       1.00      0.86      0.92        14\n",
            "          6       1.00      1.00      1.00        10\n",
            "          7       1.00      0.96      0.98        23\n",
            "          8       1.00      1.00      1.00        17\n",
            "          9       0.94      1.00      0.97        15\n",
            "         10       1.00      1.00      1.00        14\n",
            "         11       1.00      1.00      1.00        17\n",
            "         12       1.00      1.00      1.00         7\n",
            "         13       1.00      0.89      0.94        18\n",
            "         14       1.00      1.00      1.00        17\n",
            "\n",
            "avg / total       0.96      0.94      0.94       215\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UvncCXMJsmTZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "del count_vect\n",
        "del X_train_counts\n",
        "del X_test_counts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "weNNkoEGIL4e",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def get_good_tokens(sentence):\n",
        "    replaced_punctation = list(map(lambda token: re.sub('[^0-9A-Za-z!?]+', '', token), sentence))\n",
        "    removed_punctation = list(filter(lambda token: token, replaced_punctation))\n",
        "    return removed_punctation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v8hZvcESIL4i",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "data['context'] = data.context.str.lower()\n",
        "stop = nltk.corpus.stopwords.words('english')\n",
        "data['context'] = data['context'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "data['document_sentences'] = data.context.str.split('.')  # split texts into individual sentences\n",
        "data['tokenized_sentences'] = list(map(lambda sentences:\n",
        "                                     list(map(nltk.word_tokenize, sentences)),\n",
        "                                     data.document_sentences))  # tokenize sentences\n",
        "data['tokenized_sentences'] = list(map(lambda sentences:\n",
        "                                     list(map(get_good_tokens, sentences)),\n",
        "                                     data.tokenized_sentences))  # remove unwanted characters\n",
        "data['tokenized_sentences'] = list(map(lambda sentences:\n",
        "                                     list(filter(lambda lst: lst, sentences)),\n",
        "                                     data.tokenized_sentences))  # remove empty lists\n",
        "from nltk.stem.porter import *\n",
        "\n",
        "\n",
        "def stem_sentences(doc):\n",
        "    stemmer = PorterStemmer()\n",
        "    stem1 = []\n",
        "    for sentence in doc:\n",
        "        \n",
        "        stemmed_tokens = [stemmer.stem(word) for word in sentence]\n",
        "        stem1.append(stemmed_tokens)\n",
        "        \n",
        "    return stem1\n",
        "\n",
        "data['tokenized_sentences'] = data['tokenized_sentences'].apply(stem_sentences)\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "306tLHBE2Bjn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def lemm_sentences(doc):\n",
        "    lemm = WordNetLemmatizer()\n",
        "    lemm1 = []\n",
        "    for sentence in doc:\n",
        "        \n",
        "        lemmed_tokens = [lemm.lemmatize(word) for word in sentence]\n",
        "        lemm1.append(lemmed_tokens)\n",
        "        \n",
        "    return lemm1\n",
        "\n",
        "data['tokenized_sentences'] = data['tokenized_sentences'].apply(lemm_sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V62YO6TUIL4k",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a0727639-0786-45bb-80b4-28f279c45114",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531877419047,
          "user_tz": -420,
          "elapsed": 844,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "for sentence_group in data.tokenized_sentences:\n",
        "    sentences.extend(sentence_group)\n",
        "\n",
        "print(\"Number of sentences: {}.\".format(len(sentences)))\n",
        "print(\"Number of texts: {}.\".format(len(data)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences: 3539269.\n",
            "Number of texts: 1073.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tZLbBZz-IL4p",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Set values for various parameters\n",
        "num_features = 500    # Word vector dimensionality\n",
        "min_word_count = 3    # Minimum word count\n",
        "num_workers = 4       # Number of threads to run in parallel\n",
        "context = 5           # Context window size\n",
        "downsampling = 1e-3   # Downsample setting for frequent words\n",
        "\n",
        "# Initialize and train the model\n",
        "W2Vmodel = Word2Vec(sentences=sentences,\n",
        "                    workers=num_workers,\n",
        "                    size=num_features,\n",
        "                    min_count=min_word_count,\n",
        "                    window=context,\n",
        "                    sample=downsampling,\n",
        "                    negative=5,\n",
        "                    iter=6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XV4UbjHei-PN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 2134
        },
        "outputId": "dca355b0-ee64-4cf2-ffff-64ba84a95b3a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531886453698,
          "user_tz": -420,
          "elapsed": 727,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "W2Vmodel.wv['hello']"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.42043233e+00, -3.53002161e-01, -7.39032477e-02, -2.75896192e-01,\n",
              "       -4.95515503e-02, -6.60845518e-01,  2.27416590e-01,  1.06483221e+00,\n",
              "       -5.40677428e-01, -6.69867098e-02, -8.82064104e-01, -1.09640443e+00,\n",
              "        4.59125400e-01, -1.15819164e-01, -8.12985480e-01, -4.12492156e-01,\n",
              "        8.91383365e-02, -1.71566695e-01,  7.70937800e-01,  4.09874350e-01,\n",
              "        2.28674978e-01,  7.87770674e-02,  6.69027260e-03, -2.61505067e-01,\n",
              "        6.25910908e-02,  4.73773032e-02, -2.97681421e-01, -1.62618384e-01,\n",
              "        6.17842451e-02, -9.55755636e-02,  8.08296025e-01, -3.75826865e-01,\n",
              "       -2.42350355e-01,  6.99811459e-01,  1.55268729e-01, -1.72715873e-01,\n",
              "        1.24621034e+00, -3.00927162e-01,  6.17555007e-02,  1.48243951e-02,\n",
              "        3.59024294e-02,  2.46671140e-01,  5.71856499e-01,  1.94139451e-01,\n",
              "       -5.59999049e-01,  3.64143923e-02,  8.01199377e-01,  5.28571010e-02,\n",
              "       -1.76781401e-01, -6.65140092e-01,  2.04039425e-01,  3.20068777e-01,\n",
              "       -1.63228661e-01,  9.79114532e-01,  2.30069935e-01, -1.37552559e+00,\n",
              "        2.21013546e-01,  3.24894994e-01,  2.78687745e-01, -3.75751033e-02,\n",
              "       -3.86786163e-01, -4.80787069e-01, -2.03954101e-01, -5.30695200e-01,\n",
              "       -1.56192124e-01,  1.15966499e-01, -2.14003414e-01,  7.08510339e-01,\n",
              "       -4.81464744e-01,  8.98330450e-01,  2.00191066e-01,  1.62651032e-01,\n",
              "        7.81417549e-01,  3.18250358e-01, -2.38434181e-01, -2.75061131e-01,\n",
              "       -1.69899985e-01, -4.31986004e-02,  3.16948183e-02, -4.11481321e-01,\n",
              "        4.38706763e-02,  9.61170942e-02, -3.77891481e-01,  1.63468078e-01,\n",
              "       -1.65577829e-01, -5.08439422e-01, -1.17230929e-01, -1.48603410e-01,\n",
              "       -2.49838531e-01, -2.04709172e-01, -6.59338474e-01, -3.92266035e-01,\n",
              "        2.74408460e-01, -6.74512446e-01,  4.61455107e-01, -6.67300165e-01,\n",
              "        3.24347645e-01, -4.31708902e-01, -9.51124877e-02, -2.77258247e-01,\n",
              "       -6.59478724e-01,  7.27129281e-01,  1.12964228e-01, -7.89083838e-01,\n",
              "        2.95828372e-01,  1.63333461e-01, -9.44631770e-02, -8.74036252e-02,\n",
              "       -1.58091173e-01,  4.24689710e-01, -2.94191658e-01, -1.60442978e-01,\n",
              "        6.27266586e-01, -1.03732049e-01, -5.91179319e-02,  3.52662146e-01,\n",
              "        6.37335062e-01, -1.32794917e-01, -2.80183107e-01,  5.53491972e-02,\n",
              "       -1.81329139e-02,  3.98492575e-01, -5.71962357e-01, -5.33552706e-01,\n",
              "       -2.75899529e-01, -1.19314708e-01,  7.48039424e-01, -4.27830011e-01,\n",
              "       -8.29816222e-01,  2.40033448e-01,  3.94118875e-01,  1.84681162e-01,\n",
              "       -2.70296961e-01,  3.83771867e-01,  3.43315303e-01, -1.20972551e-01,\n",
              "       -6.89919945e-03, -4.69138682e-01, -2.33925939e-01, -1.99789166e-01,\n",
              "       -3.12907696e-01, -6.65712178e-01,  8.33244503e-01, -1.55091211e-01,\n",
              "        4.26999032e-01, -1.03444099e-01,  1.07310213e-01, -3.80353749e-01,\n",
              "        2.80123591e-01, -3.05960894e-01,  3.38072091e-01,  8.55238199e-01,\n",
              "        9.48359728e-01,  4.83171612e-01,  6.08877301e-01, -7.51532257e-01,\n",
              "       -1.33100057e+00,  3.14199299e-01,  2.06168666e-01, -9.87085879e-01,\n",
              "        5.03152668e-01, -7.65078604e-01,  1.04664004e+00,  4.30054754e-01,\n",
              "        5.99640869e-02,  7.79193878e-01,  2.92540807e-02, -2.48226896e-01,\n",
              "       -4.66587454e-01, -4.24174398e-01, -2.60361254e-01,  3.57739985e-01,\n",
              "        4.88947541e-01, -1.01084113e+00, -1.87479451e-01,  7.33202398e-01,\n",
              "       -1.00270301e-01, -2.98361182e-01,  1.43676868e-03,  2.43912771e-01,\n",
              "        4.35591191e-01,  2.92267531e-01,  4.94462699e-01,  3.03996921e-01,\n",
              "        1.51912048e-01, -3.39447200e-01, -5.36472738e-01,  1.96060881e-01,\n",
              "        7.70018101e-01, -3.28260809e-01,  6.28856242e-01,  1.30629182e-01,\n",
              "        3.58104408e-01,  5.23814917e-01,  8.06880355e-01, -5.70821285e-01,\n",
              "       -1.08912610e-01,  6.86438620e-01, -3.08131129e-01,  6.66193187e-01,\n",
              "        2.91747093e-01, -2.93199033e-01, -2.76961446e-01, -5.83954632e-01,\n",
              "       -3.78308386e-01,  4.95685607e-01,  1.63519979e-01, -2.50107795e-01,\n",
              "       -8.75792056e-02,  7.99693391e-02, -4.97817278e-01,  3.40954542e-01,\n",
              "        7.85649940e-02,  5.65679669e-01, -5.12910224e-02,  5.74564219e-01,\n",
              "       -6.75082743e-01,  9.31113884e-02,  8.85083899e-02, -4.01345976e-02,\n",
              "        2.90103495e-01,  7.81034753e-02, -9.77392435e-01,  2.02358782e-01,\n",
              "        2.79051304e-01,  6.69579566e-01,  1.11982417e+00, -3.39228064e-01,\n",
              "       -3.16046834e-01, -6.91750869e-02, -8.58539104e-01, -7.92750716e-02,\n",
              "       -2.95077145e-01,  7.34207511e-01, -1.01068929e-01, -8.62051368e-01,\n",
              "       -1.76240250e-01,  4.07640934e-01, -8.51184502e-02, -8.38512242e-01,\n",
              "       -3.37025493e-01,  2.47105911e-01, -2.47663811e-01, -4.26393598e-01,\n",
              "        2.73797929e-01, -1.40618877e-02, -6.37737632e-01,  8.93005505e-02,\n",
              "       -1.17565326e-01, -2.76223898e-01, -2.12787867e-01, -7.09170282e-01,\n",
              "       -1.18417956e-01,  2.04685494e-01, -2.92297065e-01, -1.96268827e-01,\n",
              "        4.97256309e-01, -3.73997033e-01, -3.16186130e-01,  1.72669962e-01,\n",
              "       -5.15496790e-01, -9.09818411e-01, -3.45913172e-01, -5.05590320e-01,\n",
              "       -6.60176337e-01, -6.83691978e-01,  1.43831506e-01,  6.25285089e-01,\n",
              "        4.83408034e-01,  3.03545833e-01,  5.97245455e-01,  4.46697593e-01,\n",
              "        4.87748720e-02,  2.67281294e-01, -1.08167015e-01, -7.00488210e-01,\n",
              "        8.73460099e-02,  5.73941529e-01, -7.37729430e-01,  5.56015968e-01,\n",
              "        2.30328063e-03,  1.52291909e-01, -4.17943627e-01,  2.77340353e-01,\n",
              "        3.07500958e-01,  1.27921030e-01,  2.93938816e-01,  5.43129332e-02,\n",
              "       -1.67190179e-01, -6.17864095e-02,  6.72152936e-02, -2.24605441e-01,\n",
              "        5.98385513e-01,  7.48756647e-01, -3.72650146e-01, -5.32055795e-01,\n",
              "       -6.43637121e-01,  1.17439136e-01,  4.14605081e-01, -2.32379973e-01,\n",
              "       -3.72334927e-01, -5.10075748e-01,  8.77091587e-02,  6.11720204e-01,\n",
              "        4.76944774e-01, -4.57379907e-01, -1.66893840e-01, -5.89963615e-01,\n",
              "       -4.39594448e-01, -5.16878068e-01,  8.73636156e-02,  2.34166116e-01,\n",
              "       -2.45441720e-01,  1.00658417e+00, -1.05661221e-01, -5.99960499e-02,\n",
              "       -3.97627205e-01, -1.85850084e-01, -3.84198874e-01,  1.14864171e-01,\n",
              "       -1.45442858e-01, -2.92420298e-01, -2.51237601e-01, -2.80598074e-01,\n",
              "        8.98309052e-02,  6.06039315e-02, -8.90537798e-02,  1.54909089e-01,\n",
              "        1.60759073e-02,  1.27756521e-01, -1.35368509e-02, -1.23765424e-01,\n",
              "        1.13298476e+00, -5.35748899e-01,  8.31109345e-01,  4.32619125e-01,\n",
              "        5.33934355e-01,  5.97441971e-01, -3.05692434e-01,  2.25778967e-01,\n",
              "        4.80658382e-01, -7.20549151e-02,  1.72415853e-01, -3.40987556e-02,\n",
              "        5.45717180e-01, -8.81159957e-03,  4.50010270e-01,  3.63951385e-01,\n",
              "        1.10582732e-01, -6.93816602e-01,  7.12287068e-01, -6.36328816e-01,\n",
              "       -6.21287227e-01, -5.04023373e-01,  9.23042074e-02,  4.58833441e-04,\n",
              "        3.18594098e-01,  2.44470283e-01,  9.61966634e-01,  5.47915138e-02,\n",
              "        7.35553280e-02,  1.90088063e-01,  5.42525053e-01, -5.41388273e-01,\n",
              "        9.70756292e-01,  8.18823934e-01,  6.70163870e-01,  2.56538779e-01,\n",
              "        3.09027821e-01,  5.26399791e-01, -1.40351161e-01, -1.90068230e-01,\n",
              "       -1.05120847e-02,  1.18426837e-01,  4.92597193e-01,  4.67681102e-02,\n",
              "       -1.00310005e-01, -4.80750740e-01, -4.46256369e-01, -8.04468930e-01,\n",
              "       -8.66271481e-02, -3.99917990e-01, -3.55617315e-01, -1.66897997e-01,\n",
              "       -1.34192443e+00,  5.52582264e-01,  7.66255260e-01,  9.24296439e-01,\n",
              "        6.17856741e-01,  1.39865920e-01, -3.51822942e-01, -2.63203442e-01,\n",
              "       -9.41276371e-01, -7.97091499e-02, -2.07844406e-01,  3.99791658e-01,\n",
              "        1.62855649e+00,  7.91779682e-02, -8.51192102e-02, -4.90972340e-01,\n",
              "        6.68569878e-02,  8.96971941e-01,  1.83618724e-01,  4.16728668e-02,\n",
              "        8.94707590e-02,  1.00271142e+00,  2.85371363e-01, -1.60814494e-01,\n",
              "        6.68625772e-01, -4.70107645e-01, -1.68425798e-01, -4.02593821e-01,\n",
              "       -4.05707777e-01, -8.14459324e-02, -8.18529546e-01,  3.12201917e-01,\n",
              "        7.41557717e-01,  6.03239000e-01,  7.60529339e-01,  4.33589309e-01,\n",
              "        5.12832701e-01, -3.51068079e-01, -3.56298923e-01, -4.03774947e-01,\n",
              "        5.43967664e-01, -1.89097002e-01,  9.76903364e-02,  7.13381171e-01,\n",
              "        4.98029321e-01, -2.32661009e-01,  3.60163264e-02, -4.19072509e-01,\n",
              "       -2.50700980e-01,  5.85809350e-01, -2.16574490e-01,  1.20217092e-02,\n",
              "       -4.41051275e-02, -5.41676320e-02,  7.39158317e-02,  6.08739376e-01,\n",
              "       -4.85649824e-01, -2.69254923e-01,  3.22280705e-01,  1.15881705e+00,\n",
              "        9.92656469e-01,  8.91476452e-01,  2.51578987e-01, -7.29462504e-01,\n",
              "        5.85876584e-01,  3.42592597e-01,  4.48420137e-01,  5.67964017e-01,\n",
              "       -5.34087466e-03, -5.06816566e-01, -1.19602002e-01,  5.55714965e-02,\n",
              "        3.03354472e-01, -2.32679397e-02, -6.41924620e-01,  1.69441581e-01,\n",
              "        1.80317789e-01,  5.93006551e-01,  1.13652378e-01,  5.30515552e-01,\n",
              "       -3.49643081e-01, -1.02919340e-02, -1.75912976e-01,  3.28045696e-01,\n",
              "       -6.35177076e-01,  6.03213847e-01,  2.71595716e-01,  2.92782962e-01,\n",
              "       -5.04327893e-01,  1.10793620e-01,  1.03542769e+00, -4.57938075e-01,\n",
              "        4.93598133e-01, -7.31239378e-01,  8.80783200e-01,  4.45472077e-02,\n",
              "        1.04457535e-01,  3.68972085e-02,  2.38975421e-01,  3.91366154e-01,\n",
              "        3.97529632e-01,  1.40458256e-01,  9.41677094e-01, -5.95880866e-01,\n",
              "        1.48504540e-01, -2.47955546e-01, -9.11619544e-01,  4.33922201e-01,\n",
              "        2.24278811e-02, -8.78803074e-01,  3.76371652e-01, -4.61825460e-01,\n",
              "        1.01525497e+00, -1.73438609e-01, -4.83059615e-01,  1.21795200e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "6r4ygyurjMKp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "9a69f5c2-6e83-4819-e248-176514011a46",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531886746726,
          "user_tz": -420,
          "elapsed": 692,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "W2Vmodel.wv.most_similar(positive='girl', topn =6)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('woman', 0.6099610328674316),\n",
              " ('damsel', 0.5801866054534912),\n",
              " ('maiden', 0.5556445717811584),\n",
              " ('child', 0.553718626499176),\n",
              " ('sister', 0.5484774112701416),\n",
              " ('frenchwoman', 0.53214430809021)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "metadata": {
        "id": "gY-rxD5wIL4t",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "a6aa6d2e-383d-4340-9ed4-8c790385aad4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531885018630,
          "user_tz": -420,
          "elapsed": 396438,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def get_w2v_features(w2v_model, sentence_group):\n",
        "   \n",
        "    words = np.concatenate(sentence_group)  # words in text\n",
        "    index2word_set = set(w2v_model.wv.vocab.keys())  # words known to model\n",
        "    \n",
        "    featureVec = np.zeros(w2v_model.vector_size, dtype=\"float32\")\n",
        "    \n",
        "    # Initialize a counter for number of words in a review\n",
        "    nwords = 0\n",
        "    # Loop over each word in the comment and, if it is in the model's vocabulary, add its feature vector to the total\n",
        "    for word in words:\n",
        "        if word in index2word_set: \n",
        "            featureVec = np.add(featureVec, w2v_model[word])\n",
        "            nwords += 1.\n",
        "\n",
        "    # Divide the result by the number of words to get the average\n",
        "    if nwords > 0:\n",
        "        featureVec = np.divide(featureVec, nwords)\n",
        "    return featureVec\n",
        "\n",
        "data['w2v_features'] = list(map(lambda sen_group:\n",
        "                                      get_w2v_features(W2Vmodel, sen_group),\n",
        "                                       data.tokenized_sentences))\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "tkMjQ-7qC_PX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "W2Vmodel.save(\"word2vec500.model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RC9OIxJ_DVIb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('word2vec500.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7E4r-4k7IL4x",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.w2v_features, data.author, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eLaUYYjfIL4z",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X_train_w2v = np.array(list(map(np.array, X_train)))\n",
        "X_test_w2v = np.array(list(map(np.array, X_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gv6SP84zIL45",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "ecf32c08-d2e8-406d-c88d-ad4c3c58624b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531885030519,
          "user_tz": -420,
          "elapsed": 2307,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc_model = RandomForestClassifier(n_estimators=100, random_state=888)\n",
        "rfc_model.fit(X_train_w2v,y_train)\n",
        "pr = rfc_model.predict(X_test_w2v)\n",
        "print(classification_report(y_test, pr))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                           precision    recall  f1-score   support\n",
            "\n",
            "              Andrew Lang       0.87      1.00      0.93        13\n",
            "         Anthony Trollope       1.00      0.80      0.89        15\n",
            "               Bret Harte       0.88      0.88      0.88         8\n",
            "          Charles Dickens       0.62      0.50      0.56        10\n",
            "     Charlotte Mary Yonge       0.93      0.82      0.87        17\n",
            "Edward Phillips Oppenheim       0.93      1.00      0.97        14\n",
            "       Edward Stratemeyer       1.00      1.00      1.00        10\n",
            "      George Alfred Henty       0.88      1.00      0.94        23\n",
            "              Henry James       1.00      0.94      0.97        17\n",
            "      Nathaniel Hawthorne       0.79      1.00      0.88        15\n",
            "           R M Ballantyne       1.00      0.93      0.96        14\n",
            "   Robert Louis Stevenson       0.74      0.82      0.78        17\n",
            "   Sir Arthur Conan Doyle       0.80      0.57      0.67         7\n",
            "     William Dean Howells       0.81      0.72      0.76        18\n",
            "    William Wymark Jacobs       0.89      0.94      0.91        17\n",
            "\n",
            "              avg / total       0.88      0.88      0.88       215\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FLyEDCK4IL4_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "f68fb27f-65da-4b68-cc43-c0a85e194b4c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531885031930,
          "user_tz": -420,
          "elapsed": 705,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "pr = gnb.fit(X_train_w2v, y_train)\n",
        "pr = gnb.predict(X_test_w2v)\n",
        "print(classification_report(y_test, pr))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                           precision    recall  f1-score   support\n",
            "\n",
            "              Andrew Lang       0.47      0.69      0.56        13\n",
            "         Anthony Trollope       0.67      0.67      0.67        15\n",
            "               Bret Harte       0.78      0.88      0.82         8\n",
            "          Charles Dickens       0.38      0.50      0.43        10\n",
            "     Charlotte Mary Yonge       0.86      0.71      0.77        17\n",
            "Edward Phillips Oppenheim       0.68      0.93      0.79        14\n",
            "       Edward Stratemeyer       1.00      0.80      0.89        10\n",
            "      George Alfred Henty       0.86      0.83      0.84        23\n",
            "              Henry James       0.94      0.94      0.94        17\n",
            "      Nathaniel Hawthorne       0.71      0.80      0.75        15\n",
            "           R M Ballantyne       0.92      0.86      0.89        14\n",
            "   Robert Louis Stevenson       0.21      0.18      0.19        17\n",
            "   Sir Arthur Conan Doyle       0.75      0.43      0.55         7\n",
            "     William Dean Howells       0.56      0.28      0.37        18\n",
            "    William Wymark Jacobs       0.73      0.94      0.82        17\n",
            "\n",
            "              avg / total       0.70      0.70      0.69       215\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WptEi_Emc8pF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 3111
        },
        "outputId": "9733eb1a-dd89-4ee7-a623-7eacffb82876",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531885041691,
          "user_tz": -420,
          "elapsed": 9465,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "    \n",
        "model.add(Dense(512, activation='relu', input_dim=X_train_w2v.shape[1]))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(15, activation='softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "            optimizer = keras.optimizers.RMSprop(),\n",
        "             metrics=['accuracy'])\n",
        "model.fit(X_train_w2v, y_train1h,\n",
        "        batch_size=128,\n",
        "        epochs=80,\n",
        "        verbose=1,\n",
        "        validation_data=(X_test_w2v, y_test1h))\n",
        "score = model.evaluate(X_test_w2v, y_test1h, verbose=0)\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "classes = model.predict_classes(X_test_w2v, batch_size = None)\n",
        "print(classification_report(y_testenc, classes))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 858 samples, validate on 215 samples\n",
            "Epoch 1/80\n",
            "858/858 [==============================] - 1s 1ms/step - loss: 2.5864 - acc: 0.1608 - val_loss: 2.2641 - val_acc: 0.3116\n",
            "Epoch 2/80\n",
            "858/858 [==============================] - 0s 84us/step - loss: 2.2079 - acc: 0.2914 - val_loss: 1.7738 - val_acc: 0.4419\n",
            "Epoch 3/80\n",
            "858/858 [==============================] - 0s 114us/step - loss: 1.9783 - acc: 0.3811 - val_loss: 2.1396 - val_acc: 0.3581\n",
            "Epoch 4/80\n",
            "858/858 [==============================] - 0s 104us/step - loss: 1.7447 - acc: 0.4277 - val_loss: 1.5602 - val_acc: 0.4837\n",
            "Epoch 5/80\n",
            "858/858 [==============================] - 0s 98us/step - loss: 1.5748 - acc: 0.4639 - val_loss: 1.4822 - val_acc: 0.5302\n",
            "Epoch 6/80\n",
            "858/858 [==============================] - 0s 103us/step - loss: 1.5555 - acc: 0.4604 - val_loss: 1.4079 - val_acc: 0.5302\n",
            "Epoch 7/80\n",
            "858/858 [==============================] - 0s 102us/step - loss: 1.3374 - acc: 0.5536 - val_loss: 1.6137 - val_acc: 0.4605\n",
            "Epoch 8/80\n",
            "858/858 [==============================] - 0s 100us/step - loss: 1.2835 - acc: 0.5734 - val_loss: 1.3743 - val_acc: 0.5628\n",
            "Epoch 9/80\n",
            "858/858 [==============================] - 0s 90us/step - loss: 1.3138 - acc: 0.5641 - val_loss: 1.1129 - val_acc: 0.6000\n",
            "Epoch 10/80\n",
            "858/858 [==============================] - 0s 109us/step - loss: 1.2059 - acc: 0.6096 - val_loss: 1.1391 - val_acc: 0.6372\n",
            "Epoch 11/80\n",
            "858/858 [==============================] - 0s 102us/step - loss: 1.0111 - acc: 0.6527 - val_loss: 1.1157 - val_acc: 0.6140\n",
            "Epoch 12/80\n",
            "858/858 [==============================] - 0s 106us/step - loss: 1.0177 - acc: 0.6503 - val_loss: 0.9418 - val_acc: 0.6791\n",
            "Epoch 13/80\n",
            "858/858 [==============================] - 0s 106us/step - loss: 0.9111 - acc: 0.6865 - val_loss: 1.0174 - val_acc: 0.6419\n",
            "Epoch 14/80\n",
            "858/858 [==============================] - 0s 111us/step - loss: 0.9282 - acc: 0.6818 - val_loss: 0.9878 - val_acc: 0.6698\n",
            "Epoch 15/80\n",
            "858/858 [==============================] - 0s 103us/step - loss: 0.8934 - acc: 0.7086 - val_loss: 1.3247 - val_acc: 0.5488\n",
            "Epoch 16/80\n",
            "858/858 [==============================] - 0s 101us/step - loss: 0.8649 - acc: 0.7016 - val_loss: 0.9183 - val_acc: 0.7209\n",
            "Epoch 17/80\n",
            "858/858 [==============================] - 0s 104us/step - loss: 0.7554 - acc: 0.7413 - val_loss: 0.7925 - val_acc: 0.7581\n",
            "Epoch 18/80\n",
            "858/858 [==============================] - 0s 102us/step - loss: 0.7338 - acc: 0.7529 - val_loss: 1.0133 - val_acc: 0.6884\n",
            "Epoch 19/80\n",
            "858/858 [==============================] - 0s 109us/step - loss: 0.6465 - acc: 0.7809 - val_loss: 0.7448 - val_acc: 0.7535\n",
            "Epoch 20/80\n",
            "858/858 [==============================] - 0s 107us/step - loss: 0.7146 - acc: 0.7529 - val_loss: 1.1602 - val_acc: 0.6512\n",
            "Epoch 21/80\n",
            "128/858 [===>..........................] - ETA: 0s - loss: 1.2472 - acc: 0.5938"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "858/858 [==============================] - 0s 108us/step - loss: 0.6696 - acc: 0.7739 - val_loss: 0.6799 - val_acc: 0.8093\n",
            "Epoch 22/80\n",
            "858/858 [==============================] - 0s 107us/step - loss: 0.4603 - acc: 0.8497 - val_loss: 0.8177 - val_acc: 0.7628\n",
            "Epoch 23/80\n",
            "858/858 [==============================] - 0s 115us/step - loss: 0.7276 - acc: 0.7611 - val_loss: 0.6341 - val_acc: 0.8093\n",
            "Epoch 24/80\n",
            "858/858 [==============================] - 0s 104us/step - loss: 0.4352 - acc: 0.8555 - val_loss: 0.5433 - val_acc: 0.8465\n",
            "Epoch 25/80\n",
            "858/858 [==============================] - 0s 96us/step - loss: 0.4982 - acc: 0.8333 - val_loss: 0.8414 - val_acc: 0.7535\n",
            "Epoch 26/80\n",
            "858/858 [==============================] - 0s 106us/step - loss: 0.3781 - acc: 0.8765 - val_loss: 0.5447 - val_acc: 0.7953\n",
            "Epoch 27/80\n",
            "858/858 [==============================] - 0s 88us/step - loss: 0.4579 - acc: 0.8636 - val_loss: 0.5194 - val_acc: 0.8279\n",
            "Epoch 28/80\n",
            "858/858 [==============================] - 0s 99us/step - loss: 0.4210 - acc: 0.8438 - val_loss: 0.9395 - val_acc: 0.7628\n",
            "Epoch 29/80\n",
            "858/858 [==============================] - 0s 93us/step - loss: 0.3905 - acc: 0.8625 - val_loss: 0.5465 - val_acc: 0.8419\n",
            "Epoch 30/80\n",
            "858/858 [==============================] - 0s 99us/step - loss: 0.4881 - acc: 0.8473 - val_loss: 0.5227 - val_acc: 0.8326\n",
            "Epoch 31/80\n",
            "858/858 [==============================] - 0s 101us/step - loss: 0.3201 - acc: 0.8951 - val_loss: 0.9562 - val_acc: 0.7581\n",
            "Epoch 32/80\n",
            "858/858 [==============================] - 0s 104us/step - loss: 0.3090 - acc: 0.8928 - val_loss: 0.7944 - val_acc: 0.7581\n",
            "Epoch 33/80\n",
            "858/858 [==============================] - 0s 103us/step - loss: 0.2663 - acc: 0.9103 - val_loss: 0.5436 - val_acc: 0.8558\n",
            "Epoch 34/80\n",
            "858/858 [==============================] - 0s 90us/step - loss: 0.3760 - acc: 0.8695 - val_loss: 0.6334 - val_acc: 0.8279\n",
            "Epoch 35/80\n",
            "858/858 [==============================] - 0s 89us/step - loss: 0.2636 - acc: 0.9219 - val_loss: 0.5475 - val_acc: 0.8512\n",
            "Epoch 36/80\n",
            "858/858 [==============================] - 0s 104us/step - loss: 0.3097 - acc: 0.8986 - val_loss: 0.4232 - val_acc: 0.8698\n",
            "Epoch 37/80\n",
            "858/858 [==============================] - 0s 88us/step - loss: 0.5288 - acc: 0.8543 - val_loss: 1.1348 - val_acc: 0.6791\n",
            "Epoch 38/80\n",
            "858/858 [==============================] - 0s 92us/step - loss: 0.3294 - acc: 0.8998 - val_loss: 0.4262 - val_acc: 0.8837\n",
            "Epoch 39/80\n",
            "858/858 [==============================] - 0s 108us/step - loss: 0.1241 - acc: 0.9639 - val_loss: 0.3920 - val_acc: 0.8884\n",
            "Epoch 40/80\n",
            "858/858 [==============================] - 0s 100us/step - loss: 0.1354 - acc: 0.9545 - val_loss: 0.5490 - val_acc: 0.8605\n",
            "Epoch 41/80\n",
            "858/858 [==============================] - 0s 101us/step - loss: 0.5379 - acc: 0.8473 - val_loss: 0.4603 - val_acc: 0.8744\n",
            "Epoch 42/80\n",
            "858/858 [==============================] - 0s 104us/step - loss: 0.1142 - acc: 0.9627 - val_loss: 0.7308 - val_acc: 0.8233\n",
            "Epoch 43/80\n",
            "858/858 [==============================] - 0s 85us/step - loss: 0.3312 - acc: 0.8881 - val_loss: 0.3805 - val_acc: 0.8884\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 44/80\n",
            "858/858 [==============================] - 0s 92us/step - loss: 0.1786 - acc: 0.9522 - val_loss: 0.4661 - val_acc: 0.8605\n",
            "Epoch 45/80\n",
            "858/858 [==============================] - 0s 97us/step - loss: 0.1522 - acc: 0.9580 - val_loss: 0.7222 - val_acc: 0.7860\n",
            "Epoch 46/80\n",
            "858/858 [==============================] - 0s 93us/step - loss: 0.2154 - acc: 0.9347 - val_loss: 0.3814 - val_acc: 0.9023\n",
            "Epoch 47/80\n",
            "858/858 [==============================] - 0s 91us/step - loss: 0.1449 - acc: 0.9522 - val_loss: 0.7281 - val_acc: 0.8372\n",
            "Epoch 48/80\n",
            "858/858 [==============================] - 0s 97us/step - loss: 0.3045 - acc: 0.9103 - val_loss: 0.3514 - val_acc: 0.9116\n",
            "Epoch 49/80\n",
            "858/858 [==============================] - 0s 104us/step - loss: 0.2249 - acc: 0.9312 - val_loss: 1.1428 - val_acc: 0.7488\n",
            "Epoch 50/80\n",
            "858/858 [==============================] - 0s 84us/step - loss: 0.3156 - acc: 0.9242 - val_loss: 0.3222 - val_acc: 0.8977\n",
            "Epoch 51/80\n",
            "858/858 [==============================] - 0s 85us/step - loss: 0.0617 - acc: 0.9872 - val_loss: 0.3736 - val_acc: 0.9070\n",
            "Epoch 52/80\n",
            "858/858 [==============================] - 0s 99us/step - loss: 0.1753 - acc: 0.9487 - val_loss: 1.3676 - val_acc: 0.7395\n",
            "Epoch 53/80\n",
            "858/858 [==============================] - 0s 102us/step - loss: 0.3683 - acc: 0.9033 - val_loss: 0.4081 - val_acc: 0.8791\n",
            "Epoch 54/80\n",
            "858/858 [==============================] - 0s 96us/step - loss: 0.0635 - acc: 0.9802 - val_loss: 0.3711 - val_acc: 0.8930\n",
            "Epoch 55/80\n",
            "858/858 [==============================] - 0s 107us/step - loss: 0.0454 - acc: 0.9872 - val_loss: 0.4381 - val_acc: 0.8977\n",
            "Epoch 56/80\n",
            "858/858 [==============================] - 0s 99us/step - loss: 0.0745 - acc: 0.9814 - val_loss: 0.7244 - val_acc: 0.8419\n",
            "Epoch 57/80\n",
            "858/858 [==============================] - 0s 101us/step - loss: 0.2593 - acc: 0.9242 - val_loss: 0.6389 - val_acc: 0.8326\n",
            "Epoch 58/80\n",
            "858/858 [==============================] - 0s 96us/step - loss: 0.3062 - acc: 0.9149 - val_loss: 0.3310 - val_acc: 0.9023\n",
            "Epoch 59/80\n",
            "858/858 [==============================] - 0s 90us/step - loss: 0.0660 - acc: 0.9814 - val_loss: 0.3848 - val_acc: 0.9163\n",
            "Epoch 60/80\n",
            "858/858 [==============================] - 0s 96us/step - loss: 0.0684 - acc: 0.9732 - val_loss: 0.5116 - val_acc: 0.8651\n",
            "Epoch 61/80\n",
            "858/858 [==============================] - 0s 83us/step - loss: 0.3905 - acc: 0.9009 - val_loss: 0.5100 - val_acc: 0.8977\n",
            "Epoch 62/80\n",
            "858/858 [==============================] - 0s 86us/step - loss: 0.0858 - acc: 0.9720 - val_loss: 0.4351 - val_acc: 0.8977\n",
            "Epoch 63/80\n",
            "858/858 [==============================] - 0s 102us/step - loss: 0.0267 - acc: 0.9918 - val_loss: 0.3947 - val_acc: 0.9209\n",
            "Epoch 64/80\n",
            "858/858 [==============================] - 0s 87us/step - loss: 0.0668 - acc: 0.9779 - val_loss: 0.4757 - val_acc: 0.8791\n",
            "Epoch 65/80\n",
            "858/858 [==============================] - 0s 86us/step - loss: 0.2713 - acc: 0.9219 - val_loss: 0.4432 - val_acc: 0.9070\n",
            "Epoch 66/80\n",
            "858/858 [==============================] - 0s 99us/step - loss: 0.2960 - acc: 0.9138 - val_loss: 0.5010 - val_acc: 0.8837\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 67/80\n",
            "858/858 [==============================] - 0s 88us/step - loss: 0.0507 - acc: 0.9825 - val_loss: 0.4346 - val_acc: 0.8884\n",
            "Epoch 68/80\n",
            "858/858 [==============================] - 0s 95us/step - loss: 0.0455 - acc: 0.9872 - val_loss: 0.4271 - val_acc: 0.9163\n",
            "Epoch 69/80\n",
            "858/858 [==============================] - 0s 95us/step - loss: 0.0492 - acc: 0.9837 - val_loss: 0.7000 - val_acc: 0.8465\n",
            "Epoch 70/80\n",
            "858/858 [==============================] - 0s 86us/step - loss: 0.3905 - acc: 0.9009 - val_loss: 0.3192 - val_acc: 0.9395\n",
            "Epoch 71/80\n",
            "858/858 [==============================] - 0s 87us/step - loss: 0.0217 - acc: 0.9953 - val_loss: 0.3238 - val_acc: 0.9349\n",
            "Epoch 72/80\n",
            "858/858 [==============================] - 0s 88us/step - loss: 0.0195 - acc: 0.9942 - val_loss: 0.5103 - val_acc: 0.8837\n",
            "Epoch 73/80\n",
            "858/858 [==============================] - 0s 101us/step - loss: 0.1997 - acc: 0.9429 - val_loss: 0.5048 - val_acc: 0.8791\n",
            "Epoch 74/80\n",
            "858/858 [==============================] - 0s 87us/step - loss: 0.1803 - acc: 0.9464 - val_loss: 0.4593 - val_acc: 0.8930\n",
            "Epoch 75/80\n",
            "858/858 [==============================] - 0s 84us/step - loss: 0.0272 - acc: 0.9953 - val_loss: 0.3084 - val_acc: 0.9302\n",
            "Epoch 76/80\n",
            "858/858 [==============================] - 0s 86us/step - loss: 0.0164 - acc: 0.9953 - val_loss: 0.4318 - val_acc: 0.9023\n",
            "Epoch 77/80\n",
            "858/858 [==============================] - 0s 100us/step - loss: 0.1521 - acc: 0.9615 - val_loss: 0.7762 - val_acc: 0.8186\n",
            "Epoch 78/80\n",
            "858/858 [==============================] - 0s 99us/step - loss: 0.3038 - acc: 0.9103 - val_loss: 0.3420 - val_acc: 0.9209\n",
            "Epoch 79/80\n",
            "858/858 [==============================] - 0s 103us/step - loss: 0.0224 - acc: 0.9953 - val_loss: 0.3883 - val_acc: 0.9209\n",
            "Epoch 80/80\n",
            "858/858 [==============================] - 0s 110us/step - loss: 0.1148 - acc: 0.9709 - val_loss: 0.3517 - val_acc: 0.9209\n",
            "Test loss: 0.3516538892201213\n",
            "Test accuracy: 0.9209302325581395\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.86      0.92      0.89        13\n",
            "          1       1.00      0.80      0.89        15\n",
            "          2       1.00      1.00      1.00         8\n",
            "          3       0.75      0.60      0.67        10\n",
            "          4       0.94      1.00      0.97        17\n",
            "          5       1.00      1.00      1.00        14\n",
            "          6       1.00      1.00      1.00        10\n",
            "          7       0.92      1.00      0.96        23\n",
            "          8       0.94      1.00      0.97        17\n",
            "          9       0.86      0.80      0.83        15\n",
            "         10       1.00      0.93      0.96        14\n",
            "         11       0.84      0.94      0.89        17\n",
            "         12       0.60      0.86      0.71         7\n",
            "         13       1.00      0.89      0.94        18\n",
            "         14       1.00      0.94      0.97        17\n",
            "\n",
            "avg / total       0.93      0.92      0.92       215\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zpk99RbRMVfl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5bNuQlrYMdFx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4YgQCdhbpJG2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}